# Clase 12: Paralelismo de tareas

```scala
import common.
import scala.util.Random
import org.scalameter.

def merge(v1: Vector[Int], v2: Vector[Int]): Vector[Int] = {
  val n1 = v1.length
  val n2 = v2.length
  if (n1 == 0) v2 
  else if (n2 == 0) v1
  else if (v1(0) < v2(0)) v1(0) +: merge(v1.slice(1, n1), v2)
  else v2(0) +: merge(v1, v2.slice(1, n2))
}

def mergeSortSeq(v: Vector[Int]): Vector[Int] = {
  val n = v.length
  val m = n/2
  if (n <= 1) v 
  else merge(mergeSortSeq(v.slice(0,m)), mergeSortSeq(v.slice(m, n)))
}

def mergeSortPar(maxProf: Int)(prof: Int)(v: Vector[Int]): Vector[Int] = {
  val n = v.length
  val m = n/2
  if (prof > maxProf) mergeSortSeq(v) 
  else {
    val (v1, v2) = parallel(mergeSortPar(maxProf)(prof+1)(v.slice(0,m)), 
                           mergeSortPar(maxProf)(prof+1)(v.slice(m, n)))
    merge(v1, v2)
  }
}
```

Resultado

```jsx
seq: 8.830642 ms
par4: 3.839996 ms
par8: 3.586142 ms
```

# Operaciones en paralelo

1. El n칰mero de hilos
    1. Esta limitado por el hardware
    2. Podemos limitar por profundidad (exponencial) o por umbral (tama침o del arreglo para resolverlo de forma secuencia)
2. Operaciones deben ser asociativas: Puedo determinar el orden en que las agrupo
3. Las listas no son las mejores para paralelizar: no son faciles de dividir por su estructura recursiva (cabeza, cola) en su lugar usar vectores o arreglos
4. Estrategias para parelizar
    1. Profundidad, cada vez que se hace un llamado aumento la profundidad en un arbol binario
    2. Umbral: Si el tama침o de la colecci칩n es menor que un valor dado se ejecuta de forma secuencial
    3. Arbol: Se construye una estructura de datos, en la cual el nodo es la parelizaci칩n y la hoja es la soluci칩n del problema

# Map

### Estrategia por umbral

```scala
val umbral = 10000

def mapASegPar[A, B](ent: Array[A],
                     izq: Int, der: Int,
                     f: A => B,
                     sal: Array[B]): Unit = {
  // Escribe en sal(i) para izq <= i <= der-1
  if (der - izq < umbral)
    mapASegSeq(ent, izq, der, f, sal)
  else {
    val mid = izq + (der - izq) / 2
    parallel(
      mapASegPar(ent, izq, mid, f, sal),
      mapASegPar(ent, mid, der, f, sal)
    )
  }
}

val e = Array(2, 3, 4, 5, 6)

```

El concepto de "umbral" en la paralelizaci칩n se refiere a un l칤mite predefinido que decide cu치ndo una tarea debe resolverse de manera secuencial en lugar de seguir dividi칠ndose en sub-tareas paralelas. Este enfoque es 칰til para evitar el overhead que genera la paralelizaci칩n en casos donde las tareas son demasiado peque침as, ya que el costo de coordinar hilos puede superar los beneficios de dividir el trabajo.

En el caso del c칩digo presentado, el umbral se utiliza para determinar si el rango de elementos (definido por `izq` y `der`) es suficientemente grande como para justificar la paralelizaci칩n. Si el rango es menor que el umbral (`der - izq < umbral`), se realiza el c치lculo de manera secuencial utilizando la funci칩n `mapASegSeq`. Por el contrario, si el rango es mayor, se divide en dos mitades (`mid`) y se procesa cada una de ellas en paralelo utilizando la funci칩n `parallel`.

El beneficio principal de esta estrategia es que combina la eficiencia de la paralelizaci칩n para tareas grandes con el bajo costo de la ejecuci칩n secuencial para tareas peque침as. Esto optimiza el rendimiento general del programa, evitando que los recursos del sistema se desperdicien en la creaci칩n y administraci칩n de hilos para tareas insignificantes.

### Estrategia por 치rboles

```scala
sealed abstract class Tree[A] {
  val size: Int
}

case class Leaf[A](a: Array[A]) extends Tree[A] {
  override val size = a.size
}

case class Node[A](l: Tree[A], r: Tree[A]) extends Tree[A] {
  override val size = l.size + r.size
}

def mapTreePar[A: Manifest, B: Manifest](t: Tree[A], f: A => B): Tree[B] = t match {
  case Leaf(a) => {
    val len = a.length
    val b = new Array[B](len)
    var i = 0
    while (i < len) {
      b(i) = f(a(i))
      i = i + 1
    }
    Leaf(b)
  }
  case Node(l, r) => {
    val (lb, rb) = parallel(mapTreePar(l, f), mapTreePar(r, f))
    Node(lb, rb)
  }
}

```

El c칩digo presentado utiliza una estructura de datos de 치rbol (`Tree`) para facilitar la paralelizaci칩n en el caso de operaciones de mapeo. A continuaci칩n, se explican las partes m치s importantes y c칩mo benefician la paralelizaci칩n:

1. **Clase Abstracta `Tree[A]` y Sus Subclases**:
    - `Tree[A]` es una clase abstracta que representa un 치rbol gen칠rico, donde cada nodo puede ser un nodo interno (`Node`) o una hoja (`Leaf`).
    - `Leaf[A]` representa las hojas del 치rbol, que contienen un arreglo (`Array[A]`) de elementos. Cada hoja tiene un tama침o (`size`), que es simplemente la cantidad de elementos en el arreglo.
    - `Node[A]` representa un nodo interno del 치rbol que conecta dos sub치rboles (`l` y `r`). El tama침o de un nodo (`size`) es la suma de los tama침os de sus sub치rboles.
2. **Funci칩n `mapTreePar`**:
    - Esta funci칩n aplica una transformaci칩n (`f: A => B`) a todos los elementos del 치rbol en paralelo.
    - Si el nodo es una hoja (`Leaf`), aplica la funci칩n `f` de manera secuencial a cada elemento del arreglo contenido en la hoja y devuelve una nueva hoja con los resultados.
    - Si el nodo es un nodo interno (`Node`), se divide el trabajo en dos sub치rboles (`l` y `r`) y aplica la funci칩n recursivamente a cada uno en paralelo utilizando `parallel`. Esto permite que las operaciones de mapeo se realicen simult치neamente en diferentes partes del 치rbol.
3. **Beneficio para la Paralelizaci칩n**:
    - **Divisi칩n de Trabajo**: La estructura en forma de 치rbol facilita dividir el trabajo en subproblemas m치s peque침os que pueden resolverse en paralelo. Cada nodo maneja la paralelizaci칩n de sus sub치rboles.
    - **Escalabilidad**: Al dividir el 치rbol en m칰ltiples niveles, se maximiza el uso de los recursos disponibles (como los hilos del sistema) y se reduce el tiempo total de ejecuci칩n.
    - **Eficiencia en 츼rboles Grandes**: Para 치rboles con muchos elementos, la paralelizaci칩n permite procesar diferentes ramas simult치neamente, lo cual es mucho m치s r치pido que procesar los elementos de manera secuencial.

En resumen, este c칩digo utiliza la estructura de 치rbol para dividir y conquistar el problema de mapeo, logrando una soluci칩n eficiente y escalable mediante la paralelizaci칩n de las operaciones en diferentes ramas del 치rbol. Esto es especialmente 칰til para conjuntos de datos grandes, donde la ejecuci칩n secuencial ser칤a demasiado costosa en t칠rminos de tiempo.

### Reduce

Es una operaci칩n para convertir una colecci칩n es un valor, la operaci칩nes deben ser asociativas, para que cual arbol generado de el mismo resultado

- Estrategia umbral
- Estrategia arboles

```scala
sealed abstract class Tree[A]
case class Leaf[A](value: A) extends Tree[A]
case class Node[A](left: Tree[A], right: Tree[A]) extends Tree[A]

def reduce[A](t: Tree[A], f: (A, A) => A): A = t match {
  case Leaf(v) => v
  case Node(l, r) => f(reduce[A](l, f), reduce[A](r, f)) // Node -> f
}

def reducePar[A](t: Tree[A], f: (A, A) => A): A = t match {
  case Leaf(v) => v
  case Node(l, r) => {
    val (lV, rV) = parallel(reduce[A](l, f), reduce[A](r, f))
    f(lV, rV)
  }
}

```

El c칩digo presentado es una implementaci칩n para resolver el problema de reducci칩n (`reduce`) utilizando estructuras de datos en forma de 치rbol y aplicando paralelizaci칩n. Vamos a desglosarlo de manera sencilla y animada para que sea m치s f치cil de entender.

### 쯈u칠 hace este c칩digo?

1. **Estructura del 치rbol (`Tree`)**:
    - El 치rbol es una estructura jer치rquica compuesta por hojas (`Leaf`) y nodos internos (`Node`).
    - `Leaf[A]`: Representa los elementos finales del 치rbol, que contienen un valor (`value`).
    - `Node[A]`: Es un nodo interno que conecta dos sub치rboles (`left` y `right`).
2. **Reducci칩n secuencial (`reduce`)**:
    - La funci칩n `reduce` toma un 치rbol (`Tree[A]`) y una funci칩n asociativa `f: (A, A) => A`.
    - Si el nodo es una hoja (`Leaf`), devuelve el valor que contiene.
    - Si el nodo es un nodo interno (`Node`), aplica la funci칩n `f` a los resultados de reducir sus sub치rboles izquierdo (`left`) y derecho (`right`).
3. **Reducci칩n paralela (`reducePar`)**:
    - Similar a `reduce`, pero con un giro: los sub치rboles izquierdo y derecho se procesan en paralelo utilizando la funci칩n `parallel`.
    - Esto significa que mientras un hilo procesa el sub치rbol izquierdo, otro hilo procesa el derecho, lo que acelera el c치lculo en 치rboles grandes.

### Ventajas de usar 치rboles y paralelizaci칩n

1. **Optimizaci칩n del rendimiento**:
    - Dividir el trabajo entre sub치rboles permite aprovechar m칰ltiples n칰cleos del procesador, reduciendo el tiempo total de ejecuci칩n.
    - Es ideal para grandes vol칰menes de datos, ya que la reducci칩n secuencial puede volverse demasiado lenta.
2. **Escalabilidad**:
    - Esta estrategia escala bien con el tama침o del 치rbol y los recursos del sistema. A mayor tama침o del 치rbol, m치s trabajo se divide y se ejecuta en paralelo.
3. **Eficiencia mediante la asociatividad**:
    - La funci칩n `f` debe ser asociativa, lo que garantiza que sin importar el orden en que agrupemos las operaciones, el resultado ser치 el mismo. Esto es clave para que la paralelizaci칩n funcione correctamente.

### Ejemplo pr치ctico: 춰Anim칠monos con frutas!

Imaginen que tienen un 치rbol que representa cestas de frutas, y quieren sumar el n칰mero total de frutas. Cada hoja del 치rbol tiene un n칰mero de frutas, como:

```
Leaf(3), Leaf(5), Leaf(7), Leaf(2)

```

Estos se organizan en un 치rbol:

```
        Node
       /    \\
   Leaf(3)  Node
           /    \\
      Leaf(5)  Leaf(7)

```

Para reducir este 치rbol:

- En el nodo izquierdo, ya tenemos `Leaf(3)` -> resultado = 3.
- Para el nodo derecho:
    - Reducimos `Leaf(5)` y `Leaf(7)` en paralelo -> resultado = 5 + 7 = 12.
- Finalmente, combinamos los resultados del nodo izquierdo (3) y el derecho (12) -> resultado final = 3 + 12 = 15.

### Estudiantes aburridos, 춰an칤mense!

쯉e est치n durmiendo con tanta teor칤a? Piensen en esto como un videojuego: el 치rbol es un jefe gigante, y cada nodo o hoja es una parte del jefe que deben atacar. Usar paralelizaci칩n es como formar un equipo: cada miembro ataca una parte del jefe al mismo tiempo, 춰y as칤 lo derrotan m치s r치pido! 游

쯅o suena m치s emocionante resolver problemas as칤? 춰Manos a la obra!

# Scan

Es una operaci칩n los resultados parciales de aplicar fold a la colecci칩n

Pareciera que no se puede paralelizar por la dependencia, porque un resultado depende del anterior

Pero si podemos paralelizar usando arboles para separar la dependencia

```scala
// scanLeft paralelo con 치rboles
sealed abstract class Tree[A]
case class Leaf[A](a: A) extends Tree[A]
case class Node[A](l: Tree[A], r: Tree[A]) extends Tree[A]

// 츼rboles para guardar resultados intermedios
sealed abstract class TreeRes[A] { val res: A }
case class LeafRes[A](override val res: A) extends TreeRes[A]
case class NodeRes[A](l: TreeRes[A], override val res: A, r: TreeRes[A]) extends TreeRes[A]

// Versi칩n paralela
def llenarSubiendo[A](t: Tree[A], f: (A, A) => A): TreeRes[A] = t match {
  case Leaf(v) => LeafRes(v)
  case Node(l, r) => {
    val (tL, tR) = parallel(llenarSubiendo(l, f), llenarSubiendo(r, f))
    NodeRes(tL, f(tL.res, tR.res), tR)
  }
}

def llenarBajando[A](t: TreeRes[A], a0: A, f: (A, A) => A): Tree[A] = t match {
  case LeafRes(a) => Leaf(f(a0, a))
  case NodeRes(l, _, r) => {
    val (tL, tR) = parallel(
      llenarBajando(l, a0, f),
      llenarBajando(r, f(a0, l.res), f)
    )
    Node(tL, tR)
  }
}

def scanLeft[A](t: Tree[A], a0: A, f: (A, A) => A): Tree[A] = {
  val tRes = llenarSubiendo(t, f)
  val scan1 = llenarBajando(tRes, a0, f)
  prepend(a0, scan1)
}

```

### Ejemplo pr치ctico de `scanLeft` paralelo

Supongamos que tenemos un 치rbol con los siguientes valores:

```
        Node
       /    \\\\
   Node      Node
  /   \\\\     /   \\\\
Leaf(1) Leaf(2) Leaf(3) Leaf(4)

```

Queremos aplicar `scanLeft` con un valor inicial `a0 = 0` y la operaci칩n suma (`f(a, b) = a + b`). A continuaci칩n, mostramos el proceso paso a paso:

---

### 1. **Fase de "Llenado Subiendo" (`llenarSubiendo`)**

En esta fase, calculamos los resultados acumulados hacia arriba en el 치rbol:

1. **En las hojas**:
    - `Leaf(1) -> LeafRes(1)`
    - `Leaf(2) -> LeafRes(2)`
    - `Leaf(3) -> LeafRes(3)`
    - `Leaf(4) -> LeafRes(4)`
2. **En los nodos internos** (se calculan en paralelo):
    - `Node(Leaf(1), Leaf(2)) -> NodeRes(LeafRes(1), 1 + 2 = 3, LeafRes(2))`
    - `Node(Leaf(3), Leaf(4)) -> NodeRes(LeafRes(3), 3 + 4 = 7, LeafRes(4))`
3. **En la ra칤z del 치rbol**:
    - `Node(Node(1, 2), Node(3, 4)) -> NodeRes(NodeRes(LeafRes(1), 3, LeafRes(2)), 3 + 7 = 10, NodeRes(LeafRes(3), 7, LeafRes(4)))`

El 치rbol resultante de esta fase es:

```
        NodeRes(10)
       /         \\\\
   NodeRes(3)   NodeRes(7)
  /      \\\\      /      \\\\
LeafRes(1) LeafRes(2) LeafRes(3) LeafRes(4)

```

---

### 2. **Fase de "Llenado Bajando" (`llenarBajando`)**

En esta fase, propagamos los resultados parciales hacia abajo y calculamos los valores acumulados:

1. **En la ra칤z del 치rbol**:
    - Comenzamos con el valor inicial `a0 = 0`.
2. **En los nodos internos** (se calculan en paralelo):
    - Para `NodeRes(3)`:
        - `a0_left = 0`
        - `Leaf(1) -> f(0, 1) = 1`
        - `Leaf(2) -> f(1, 2) = 3`
    - Para `NodeRes(7)`:
        - `a0_right = f(0, 3) = 3`
        - `Leaf(3) -> f(3, 3) = 6`
        - `Leaf(4) -> f(6, 4) = 10`

El 치rbol final despu칠s de esta fase es:

```
        Node
       /    \\\\
   Node      Node
  /   \\\\     /   \\\\
Leaf(1) Leaf(3) Leaf(6) Leaf(10)

```

---

### 3. **Resultado de `scanLeft`**

Finalmente, despu칠s de agregar el valor inicial `a0 = 0` al inicio, el resultado completo de `scanLeft` es:

```
[0, 1, 3, 6, 10]

```

---

### Resumen del proceso

1. **Fase de llenado subiendo**:
    - Calculamos resultados acumulados desde las hojas hacia la ra칤z.
    - Los resultados son almacenados en nodos de tipo `TreeRes`.
2. **Fase de llenado bajando**:
    - Propagamos los resultados parciales desde la ra칤z hacia las hojas.
    - Calculamos los valores acumulados en cada hoja.
3. El resultado es una secuencia acumulada que incluye el valor inicial `a0`.

Este enfoque aprovecha la paralelizaci칩n para dividir el trabajo entre sub치rboles, logrando un c치lculo eficiente incluso para 치rboles grandes. 游

### Ejemplo pr치ctico de `scanLeft` paralelo con el 치rbol `List(2,4,6,8,10,12,14,16,18)` y acumulador inicial `a0 = 100`

Supongamos que queremos aplicar `scanLeft` paralelo al conjunto de datos `List(2,4,6,8,10,12,14,16,18)` utilizando un 치rbol binario y un acumulador inicial `a0 = 100`. La operaci칩n de acumulaci칩n ser치 la suma.

---

### Paso 1: Representaci칩n inicial del 치rbol

Primero, representamos la lista como un 치rbol binario balanceado:

```
          Node
       /         \\
    Node         Node
   /    \\       /    \\
Node   Node   Node   Node
 / \\    / \\    / \\    / \\
2   4  6   8  10 12  14  16 18

```

Cada hoja contiene un valor de la lista original.

---

### Paso 2: Fase de "Llenado Subiendo" (`llenarSubiendo`)

En esta fase, calculamos los resultados acumulados hacia arriba en el 치rbol utilizando la operaci칩n de suma. Esto se realiza en paralelo para cada par de nodos:

1. **Nodos hoja (`Leaf`)**:
    - `Leaf(2) -> LeafRes(2)`
    - `Leaf(4) -> LeafRes(4)`
    - `Leaf(6) -> LeafRes(6)`
    - `Leaf(8) -> LeafRes(8)`
    - `Leaf(10) -> LeafRes(10)`
    - `Leaf(12) -> LeafRes(12)`
    - `Leaf(14) -> LeafRes(14)`
    - `Leaf(16) -> LeafRes(16)`
    - `Leaf(18) -> LeafRes(18)`
2. **Niveles superiores del 치rbol (en paralelo)**:
    - `Node(LeafRes(2), LeafRes(4)) -> NodeRes(LeafRes(2), 2 + 4 = 6, LeafRes(4))`
    - `Node(LeafRes(6), LeafRes(8)) -> NodeRes(LeafRes(6), 6 + 8 = 14, LeafRes(8))`
    - `Node(LeafRes(10), LeafRes(12)) -> NodeRes(LeafRes(10), 10 + 12 = 22, LeafRes(12))`
    - `Node(LeafRes(14), LeafRes(16)) -> NodeRes(LeafRes(14), 14 + 16 = 30, LeafRes(16))`
    - `Node(LeafRes(30), LeafRes(18)) -> NodeRes(LeafRes(30), 30 + 18 = 48, LeafRes(18))`
3. **Ra칤z del 치rbol**:
    - `Node(NodeRes(6), NodeRes(14)) -> NodeRes(NodeRes(6), 6 + 14 = 20, NodeRes(14))`
    - `Node(NodeRes(22), NodeRes(48)) -> NodeRes(NodeRes(22), 22 + 48 = 70, NodeRes(48))`
    - `Node(NodeRes(20), NodeRes(70)) -> NodeRes(NodeRes(20), 20 + 70 = 90, NodeRes(70))`

El 치rbol resultante es:

```
          NodeRes(90)
       /               \\
    NodeRes(20)       NodeRes(70)
   /       \\          /         \\
NodeRes(6) NodeRes(14) NodeRes(22) NodeRes(48)
 / \\      / \\         / \\        / \\
2   4    6   8      10  12     14  16  18

```

---

### Paso 3: Fase de "Llenado Bajando" (`llenarBajando`)

Ahora propagamos los resultados parciales hacia abajo para calcular los valores acumulados en cada hoja:

1. **Ra칤z del 치rbol**:
    - Comenzamos con el acumulador inicial `a0 = 100`.
2. **Nodos internos (en paralelo)**:
    - Para `NodeRes(20)`:
        - `a0_left = 100`
        - `NodeRes(6):`
            - `Leaf(2) -> f(100, 2) = 102`
            - `Leaf(4) -> f(102, 4) = 106`
        - `NodeRes(14):`
            - `Leaf(6) -> f(106, 6) = 112`
            - `Leaf(8) -> f(112, 8) = 120`
    - Para `NodeRes(70)`:
        - `a0_right = f(100, 20) = 120`
        - `NodeRes(22):`
            - `Leaf(10) -> f(120, 10) = 130`
            - `Leaf(12) -> f(130, 12) = 142`
        - `NodeRes(48):`
            - `Leaf(14) -> f(142, 14) = 156`
            - `Leaf(16) -> f(156, 16) = 172`
            - `Leaf(18) -> f(172, 18) = 190`

El 치rbol final despu칠s de esta fase es:

```
          Node
       /         \\
    Node         Node
   /    \\       /    \\
Node   Node   Node   Node
 / \\    / \\    / \\    / \\
102 106 112 120 130 142 156 172 190

```

---

### Paso 4: Resultado final de `scanLeft`

Despu칠s de agregar el valor inicial `a0 = 100` al inicio, el resultado completo de `scanLeft` es:

```
[100, 102, 106, 112, 120, 130, 142, 156, 172, 190]

```

---

### Resumen

El proceso de `scanLeft` paralelo divide el trabajo en dos fases principales:

1. **Llenado Subiendo**: Acumulamos los resultados parciales desde las hojas hasta la ra칤z.
2. **Llenado Bajando**: Propagamos los resultados acumulados desde la ra칤z hasta las hojas.

Este enfoque utiliza paralelizaci칩n para optimizar el c치lculo en 치rboles grandes, reduciendo significativamente el tiempo de ejecuci칩n. 游

# Resumen: Paralelismo de Tareas y Operaciones

## Aspectos m치s importantes

El documento explora estrategias de paralelizaci칩n aplicadas a distintas operaciones como `mergeSort`, `map`, `reduce`, y `scan`, utilizando estructuras de datos como listas, vectores, y 치rboles. Se destacan las siguientes ideas clave:

1. **Paralelismo y l칤mites del hardware**:
    - El n칰mero de hilos est치 limitado por el hardware.
    - Estrategias como profundidad o umbral ayudan a optimizar el desempe침o.
2. **Estrategias de paralelizaci칩n**:
    - **Por profundidad**: Incrementa la profundidad en un 치rbol binario con cada llamada recursiva.
    - **Por umbral**: Usa ejecuci칩n secuencial cuando el tama침o de la colecci칩n es menor a un valor predefinido.
    - **Por 치rboles**: Divide las operaciones en nodos y hojas, facilitando la paralelizaci칩n.
3. **Operaciones vistas**:
    - **Merge Sort**:
        - Secuencial (`mergeSortSeq`) y paralela (`mergeSortPar`).
        - Divide el vector en mitades y combina los resultados en paralelo.
    - **Map**:
        - Utiliza estrategias de umbral y 치rboles para transformar colecciones.
    - **Reduce**:
        - Convierte colecciones en un 칰nico valor utilizando funciones asociativas.
        - Implementado con 치rboles para dividir y combinar resultados en paralelo.
    - **Scan**:
        - Genera resultados parciales de un `fold` aplicando un 치rbol para separar dependencias.
4. **Importancia de la asociatividad**:
    - Las operaciones deben ser asociativas para garantizar resultados consistentes en cualquier orden de agrupaci칩n.

## Caracter칤sticas

- **Eficiencia**: Usar estructuras como 치rboles mejora la divisi칩n del trabajo y maximiza el uso de recursos.
- **Modularidad**: Las operaciones est치n dise침adas para ser reutilizables y adaptables a diferentes contextos.
- **Escalabilidad**: Permite manejar grandes vol칰menes de datos aprovechando m칰ltiples n칰cleos del procesador.

## Ventajas

- **Optimizaci칩n del rendimiento**: Reduce tiempos de ejecuci칩n al paralelizar tareas en colecciones grandes.
- **Flexibilidad**: Combina ejecuci칩n secuencial y paralela seg칰n el tama침o de la tarea.
- **Uso eficiente de recursos**: Evita el overhead de paralelizaci칩n en tareas peque침as gracias al umbral.

## Desventajas

- **Complejidad**: Implementar paralelizaci칩n requiere dise침ar estrategias cuidadosas y manejar dependencias.
- **Sobrecarga inicial**: En tareas peque침as, la paralelizaci칩n puede no ser eficiente debido al costo de coordinar hilos.
- **Requerimientos de hardware**: El rendimiento depende de la capacidad del hardware disponible.

En resumen, el documento destaca c칩mo aplicar paralelizaci칩n de manera eficiente para resolver problemas computacionales complejos, maximizando el uso de los recursos del sistema mientras se minimizan los costos asociados a la coordinaci칩n de tareas paralelas.

춰츼nimo, estudiantes! Sabemos que la vida (y los algoritmos paralelos) puede ser complicada, pero recuerden que aprender algo nuevo siempre es una forma de avanzar. Si recientemente pasaron por un mal momento, como una ruptura, consideren que incluso los sistemas m치s complejos, como el paralelismo, necesitan un balance para funcionar. T칩mense su tiempo, respiren profundo y sigan adelante, porque la vida, al igual que este documento, siempre tiene m치s cap칤tulos por escribir. 춰Ustedes pueden con esto y m치s! 游